<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Keyword Extraction</title>
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header>
      <nav>
        <h1>Keyword Extraction</h1>
        <ul>
          <li><a href="#Introduction">Introduction</a></li>
          <li><a href="#Hrank">HRANK</a></li>
          <li><a href="#Drank">DRANK</a></li>
          <li><a href="#Webrank">WebRank</a></li>
          <li><a href="#Acirank">ACI-Rank</a></li>
        </ul>
      </nav>
    </header>

    <main>
      <section id="Introduction">
        <div class="container">
          <div class="title">
            <h2>About Keyword Extraction</h2>
            <article>
              <p>
                Google defnes a keyword as an isolated word or phrase that
                provides concise high-level information about content to readers
                . With the increasing amount of data, users need more resources
                and time to understand content. Keywords make it easier to
                understand the meaning of a text in fewer words.
              </p>
              <p>
                In short, keywords summarize the key points presented in the
                text. When searching for information on search engines, keywords
                play a signifcant role in fnding relevant content. Keywords are
                the mostinformative part of a text; they are the most prominent
                words in the text and describe its content. Keywords are
                necessary in situations involving huge amounts of text data that
                need to be processed automatically. Keywords are widely used in
                document summarization, indexing, categorization, and clustering
                of huge datasets. Many scientifc publications contain keyword
                lists that have been explicitly assigned by their authors. Other
                documents, however, have not been assigned keywords . As
                webpages are constantly updated, it is difcult to create
                keywords manually. Manual keyword assignment is labor intensive,
                time consuming, and error prone.
              </p>
              <p>
                Specialized curators use fxed taxonomies for manual keyword
                generation, but in some cases, the keywords chosen by the author
                are not sufciently comprehensive and accurate. Without
                high-quality keywords, users fail to catch relevant information
                . Keywords ofer readers a concise high-level summary of a
                documents content, thereby improving their understanding of that
                text. Keywords are the most relevant and important indicator for
                users seeking to grasp the fundamentals of a topic when scanning
                or skimming an article. Keyword extraction is a basic step in
                many text-mining and natural language processing (NLP)
                techniques, including text summarization, information retrieval,
                topic modeling, clustering, and content-based advertisement
                systems. Finding the relevant webpages, a user is seeking is
                often a challenging task for which representative keywords or
                keyphrases.
              </p>

              <p>
                This article addresses the issue of automatic extracting
                keywords from webpages. The majority of existing keyword
                extraction methods use language-dependent Natural Language
                Processing (NLP) based techniques, including Part-of-Speech
                (POS) tagging, stemming, and lemmatization, which makes it
                complex to generalize a method for different languages. The main
                purpose of the research is to extract only those
                language-independent features of web pages in order to find a
                method that can be applied in different languages.
              </p>
              <p>
                So far, studies on language-independent approaches have been
                limited because they usually perform worse than methods that
                take advantage of linguistic features. Extracting keywords from
                web documents involves two main challenges: the first is the
                presence of noise and irrelevant data such as navigation bars,
                menus, comments and advertisements and the second consists in
                the presence of multiple topics and multiple languages.
                Therefore, it is very important to have a general keyword
                extraction method that can extract keywords without relying on
                any specific language.
              </p>

              <p>
                addresses the challenges of keyword extraction by developing and
                testing four new techniques, both language-dependent and
                language-independent as well as supervised and unsupervised.
                Special attention is paid to finding the most relevant features
                for identifying good keyword and keyphrase candidates. The work
                deals with statistical, linguistic, and structural features as
                well as their combinations. This diversity of approaches serves
                the pragmatic overall goal of finding the best available methods
                by assessing the relative performances of the newly developed as
                well as existing methods on a number of different datasets.
              </p>

              <p>
                For this purpose the author proposes four new automatic keyword
                extraction methods for webpages: Hrank, D-rank, WebRank, and
                ACI-rank
              </p>
            </article>
          </div>
        </div>
      </section>

      <section id="Hrank">
        <div class="container">
          <div class="title">
            <h2>HRANK</h2>
            <article>
              <p>
                we study the importance of the distribution of semantically similar POS tags, such as nouns, adjectives, and verbs in the extraction of relevant keywords from the web page
              </p><p><li>	A new keywords extraction method that requires a minimum knowledge of DOM structure. </li>
                <li>A simple measure TF performs better than the more complex methods. </li>
                  <li>However, the combination of nouns, adjectives, and verbs improves performance when TF fails.</li>
                 
<li> A new keywords extraction method that requires a minimum knowledge of DOM structure. </li>
<li>The proposed method outperforms CL-Rank, TextRank, and TF. A simple measure TF performs better than the more complex methods. However, the combination of nouns, adjectives, and verbs improves performance when TF fails.</li>
</p>               
                

                
              
            </article>
          </div>
          <div class="methodology">
            <div class="title"><h3>Methodology </h3></div>
            <article>
              <p>Fig. 1. presents the workflow of the proposed keywords extraction method. The method has two modules: (1) pre-processing and (2) keyword extraction. The pre-processing module involves the extraction of the natural language text from the web page. The keyword extraction module utilizes the text from the pre-processing module. 
                In the pre-processing module, the first three functions involve the filtering of the text from all the other content of a web page. All the content of a web page is extracted using a document object model (DOM) and X-path function. The text that belongs to javascript scripting language and cascade style sheets is eliminated in the text filtering function. The special characters, such as @,*,Â£, or $, punctuation marks, and numbers are also filtered out using the regular expression in the text filtering function. Similarly, the text filtering function also involves the removal of the stop words from the text. The stop words are the natural language words that have minimal or no meaning, such as and, the, a, and an. The filtered text can now be utilized for natural language processing.
                The POS extractor, normalize text, and separate POS functions involve the natural language processing on the filtered text. The POS extractor function divides the text into tokens. A token is a whitespace-separated unit of text. The tokens are assigned the POS tags, such as nouns, adjectives, and verbs. 
                <p>  <img
                  src="./images/Hrank_workflow.PNG"
                  alt="Dranks"
                  width="600"
                  height="300"
                />
                <p>Fig. 1. Workflow of Drank</p></p>
                <p>The tokens with POS tags are further normalized.
                 The normalization is the process of replacing the inflected forms of a word with the root word. The inflected form represents the different usage of a word in the sentences. For example, finds, finding, and found are the inflected forms of the word find. An inflected form of a word has a changed spelling or ending. In natural language processing, the lemmatization is used to find the inflected form of the words with different spellings, such as finds and found for the word find in the above example. Unlike lemmatization, the stemming process takes care of the prefixes and suffixes to find the root word, such as finding in the abovementioned example. The output of the normalization process is the tokens with all the inflected forms replaced with their root word.
                The lists of the POS-tagged tokens are provided to the separate POS function, which separates the tokens into the lists of nouns, adjectives, and verbs. The lists are provided to the count frequency function. The count frequency function calculates the frequency of the words in the separate lists having nouns, adjectives, and verbs. The top-frequent tokens are selected as candidate keywords. The semantically similar words among top-frequent tokens are grouped together using a lexical database, named as WordNet. The lexical database helps in finding the synsets of the words. The synset is a set of one or more synonyms that can be used interchangeably in some context [20].                                                                                                                                                                                                                                                                                                                                                                                                                            
              </p>
              <p>
              We compute the semantic similarity of two different words using path-similarity, which is based on the WordNet [21]. The words that have no synonyms in the WordNet are removed from the lists. The path-similarity metric calculates the score between two different words in terms of their relatedness. We use path-similarity because it is very simple and it operates based on a parent-child relationship like a tree. Therefore, it is more convenient to use in our case.
                Three similarity matrices are created independently for the nouns, adjectives, and verbs. The similarity matrices are utilized in clustering the related words. We use an agglomerative clustering to find similar words in the lists.  The clusters are scored by counting the frequencies of all the words in each cluster. The clusters are ranked according to the scores.
                </p>  
            </article>
          </div>
          <div class="coding">
            <h3>Python Implementation</h3>
             <p><ol>
              <li>Extract Text</li>
              <li>Preprocess Text</li>
              <li>POS Tags Seperation</li>
              <li>Word Net semantic similarity</li>
              <li>Cluster Words</li>
              <li>Keyword Ranking and Selection</li>
            </ol></p>
            <pre><code>
              
              <h4> Import packages</h4>
              
              <code> Imports
                import urllib
                import nltk
                import sys
                import re 
                
                import lxml
                import math
                import string
                import textwrap
                import requests
                
                from nltk.corpus import stopwords
                from bs4 import BeautifulSoup
                from nltk import word_tokenize
                from nltk.stem import WordNetLemmatizer
                from collections import defaultdict,Counter
                from nltk.corpus import stopwords
                from collections import defaultdict 
                from bs4.element import Comment
                
                from nltk import wordpunct_tokenize
                from urllib.parse import urlparse 
                
                import pandas as pd 
                import numpy as np
                
                Common_Nouns ="january debt est dec big than who use jun jan feb mar apr may jul agust dec oct nov sep dec  product continue second secodns".split(" ")
                URL_CommnWords =['','https','www','com','-','php','pk','fi','http:','http']
                URL_CommonQueryWords = ['','https','www','com','-','php','pk','fi','https:','http','http:','html','htm']
                UselessTagsText =['html','style', 'script', 'head',  '[document]','img']
                <hr class ="new3"/>
        <h4>(1) Extract Text of Webpage</h4>
       
                
                def Scrapper1(element):
                    if element.parent.name in [UselessTagsText]:
                        return False
                    if isinstance(element, Comment):
                        return False
                    return True
                
                def Scrapper2(body):             
                    soup = BeautifulSoup(body, 'lxml')      
                    texts = soup.findAll(text=True)   
                    name =soup.findAll(name=True) 
                    visible_texts = filter(Scrapper1,texts)        
                    return u" ".join(t.strip() for t in visible_texts)
                
                def Scrapper3(text):                  
                    lines = (line.strip() for line in text.splitlines())    
                    chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                    return u'\n'.join(chunk for chunk in chunks if chunk)
                
                
                def Scrapper_title_4(URL):
                  req = urllib.request.Request(URL, headers={'User-Agent' : "Magic Browser"})
                  con = urllib.request.urlopen(req)
                  html= con.read()
                  title=[]
                  
                  soup = BeautifulSoup(html, 'lxml') 
                  title.append(soup.title.string)
                  return(title,urls)
                
                def Web_Funtion(URL):
                  req = urllib.request.Request(URL, headers={'User-Agent' : "Magic Browser"})
                  con = urllib.request.urlopen(req)
                  html= con.read()  
                  Raw_HTML_Soup = BeautifulSoup(html, 'lxml') 
                 
                  raw =Scrapper2(html)
                  Raw_text = Scrapper3(raw) 
                  return(Raw_text,Raw_HTML_Soup)  
                
              
                
                    </code></pre>
          </div>
          <div class="output">
            <div class="result">
              <h4></h4>
              <pre><code></code></pre>
            </div>
          </div>
        </div>
      </section>

      <section id="Drank">
        <div class="container">
          <div class="title">
            <h2>DRANK</h2>
            <article>
              <p>
                Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
                eiusmod tempor incididunt ut labore et dolore magna aliqua.
              </p>
              <p>
                Ut enim ad minim veniam, quis nostrud exercitation ullamco
                laboris nisi ut aliquip ex ea commodo consequat.
              </p>
            </article>
          </div>
          <div class="methodology">
            <div class="title"><h3>Methodology DRANK</h3></div>
            <article>
              <p>
                Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
                eiusmod tempor incididunt ut labore et dolore magna aliqua.
              </p>
              <
            </article>
          </div>
        </div>
      </section>

      <section id="Webrank">
        <div class="container">
          <div class="title">
            <h2>WebRank</h2>
            <article>
              <p>
                Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
                eiusmod tempor incididunt ut labore et dolore magna aliqua.
              </p>
              <p>
                Ut enim ad minim veniam, quis nostrud exercitation ullamco
                laboris nisi ut aliquip ex ea commodo consequat.
              </p>
            </article>
          </div>
          <div class="methodology">
            <div class="title"><h3>Methodology DRANK</h3></div>
            <article>
              <p>
                Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
                eiusmod tempor incididunt ut labore et dolore magna aliqua.
              </p>
              <
            </article>
          </div>
        </div>
      </section>

      <section id="Acirank">
        <div class="container">
          <div class="title">
            <h2>ACIRANK</h2>
            <article>
              <p>
                Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
                eiusmod tempor incididunt ut labore et dolore magna aliqua.
              </p>
              <p>
                Ut enim ad minim veniam, quis nostrud exercitation ullamco
                laboris nisi ut aliquip ex ea commodo consequat.
              </p>
            </article>
          </div>
          <div class="methodology">
            <div class="title"><h3>Methodology DRANK</h3></div>
            <article>
              <p>
                Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
                eiusmod tempor incididunt ut labore et dolore magna aliqua.
              </p>
              <
            </article>
          </div>
        </div>
      </section>
    </main>
  </body>
</html>
